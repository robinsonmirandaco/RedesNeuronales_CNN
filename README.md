# ğŸ“Œ ClasificaciÃ³n de ImÃ¡genes CIFAR-10 con Redes Neuronales Convolucionales  
### MÃ¡ster Universitario en Inteligencia Artificial â€“ UNIR  
### Actividad Individual â€“ Redes Neuronales  
**Estudiante:** Robinson Miranda  

---

## ğŸ“– DescripciÃ³n del proyecto

Este repositorio contiene el desarrollo completo de la actividad individual sobre **Redes Neuronales Convolucionales (CNN)** aplicada al dataset **CIFAR-10**.  
El objetivo principal es entrenar, comparar y analizar distintas arquitecturas de redes neuronales para clasificar imÃ¡genes en 10 categorÃ­as.

El proyecto incluye:

- anÃ¡lisis exploratorio del dataset,
- entrenamiento de un modelo *fully connected* como baseline,
- construcciÃ³n de diferentes modelos CNN,
- uso de *Batch Normalization* y *Dropout*,
- implementaciÃ³n de *data augmentation*,
- evaluaciÃ³n con mÃ©tricas por clase y matriz de confusiÃ³n,
- anÃ¡lisis visual de errores.

Este trabajo fue realizado como parte del MÃ¡ster en Inteligencia Artificial de UNIR.

---

## ğŸ¯ Objetivos

- Comprender las limitaciones de un modelo totalmente conectado en visiÃ³n por computador.
- Evaluar mejoras progresivas mediante arquitecturas convolucionales.
- Aplicar tÃ©cnicas de regularizaciÃ³n y normalizaciÃ³n.
- Analizar el comportamiento del modelo mediante mÃ©tricas, grÃ¡ficas y visualizaciones.
- Construir un modelo CNN robusto que generalice correctamente sobre CIFAR-10.

---

## ğŸ—‚ Dataset: CIFAR-10

- 60 000 imÃ¡genes en color (32Ã—32 px)
- 10 clases balanceadas:
  `aviÃ³n, coche, ave, gato, ciervo, perro, rana, caballo, barco, camiÃ³n`
- 50 000 imÃ¡genes para entrenamiento (de las cuales se separan 10 000 para validaciÃ³n)
- 10 000 imÃ¡genes para test

---

## ğŸ§ª Modelos implementados

### 1ï¸âƒ£ **Modelo Fully Connected (Baseline)**  
- Imagen aplanada â†’ capas densas de 512 y 256 neuronas  
- Dropout  
- ~1.7 millones de parÃ¡metros  
- **Exactitud en test:** ~35 % (se usa solo como punto de partida)

---

### 2ï¸âƒ£ **CNN Simple**
- 3 bloques Conv2D + MaxPooling  
- Capa densa final  
- **Exactitud en test:** ~74 %

---

### 3ï¸âƒ£ **CNN Profunda con BatchNorm + Dropout**
- Bloques convolucionales con Batch Normalization  
- Capas de Dropout para reducir sobreajuste  
- Capa densa de 512 neuronas  
- **Exactitud en test:** ~80 %  
- **PÃ©rdida en test:** ~0.58  

Este modelo es el mejor del proyecto.

---

## ğŸ“Š MÃ©tricas (modelo final)

- **Accuracy global:** ~81 %
- **Clases mejor clasificadas:** coche, camiÃ³n, barco  
- **Clases con mÃ¡s confusiÃ³n:** ave, gato, perro  
- **Recall destacado:** rana (0.95), caballo (0.91), aviÃ³n (0.90)

---

## ğŸ” Matriz de confusiÃ³n

(Insertar imagen aquÃ­ si la subes al repo)

---

## ğŸ‘ï¸ AnÃ¡lisis visual de errores

(Insertar imagen aquÃ­ si la subes al repo)

Los errores se concentran en:

- animales con fondos complejos,
- imÃ¡genes poco definidas,
- confusiones entre especies (gato â†” perro, ave â†” gato),
- posiciones o colores atÃ­picos.

---

## ğŸ“ˆ GrÃ¡ficas de entrenamiento

Se incluyen:

- pÃ©rdida y accuracy del modelo fully connected  
- desempeÃ±o de la CNN simple  
- curvas del modelo final con *data augmentation*  

(Insertar imÃ¡genes si las agregas al repo)

---

## ğŸ Conclusiones

- Las CNN superan ampliamente a los modelos totalmente conectados en visiÃ³n por computador.  
- Batch Normalization y Dropout ayudan a estabilizar y controlar el sobreajuste.  
- Data augmentation genera mejoras reales en la capacidad de generalizaciÃ³n.  
- El modelo final alcanza un rendimiento competitivo para ser una arquitectura construida desde cero.  
- El anÃ¡lisis de clases y errores permite entender los lÃ­mites reales del modelo.

---


---

## ğŸ›  TecnologÃ­as utilizadas

- Python  
- TensorFlow / Keras  
- NumPy  
- Matplotlib  
- Scikit-learn  

---


**Robinson Miranda**  
MÃ¡ster Universitario en Inteligencia Artificial â€“ UNIR  

